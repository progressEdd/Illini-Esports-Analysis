---
title: "Exam 2"
output:
  pdf_document: default
  word_document: default
---
# EDA
## Load the data
```{r}
library(readxl)
df <- read_excel("Test 2 ICO.xlsx")
df
```

## Loading the packages
```{r}
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
set.seed(10)
```

## Splitting the training data
```{r}
?createDataPartition
trainIndex <- createDataPartition(df$USDRaised, p = 0.8, list = FALSE, times = 1)
trainIndex

trainset <- df[trainIndex,]
testset <- df[-trainIndex,]
trainset
testset
```

# 1. Report the decision tree graph (before and after pruning)

## before pruning
```{r}
tree <- rpart(USDRaised ~ . , trainset, method = "class")
plot(tree)
text(tree)
tree
```
```{r}
plot_pre_prune = rpart.plot(tree, type=4, cex =.8, digits = -3)
plot_pre_prune
```
## after pruning
### tree prediction

```{r}
predict_tree <- predict (tree, testset, type="class")
predict_tree
```

### checking relative errror plot
```{r}
printcp(tree)
plotcp(tree)
```
### pruning it
```{r}
ptree <- prune(tree, cp = tree$cptable[which.min(tree$cptable[,"xerror"]), "CP"])
post_prune = rpart.plot(ptree, type=4,cex=.8, digits = -3)
post_prune
```
# 3. Write down the decision rules after pruning in plain English
if you want your ico to succeed, the `TokenSalePrice` should be >= 0.005
  otherwise if `TokenSalePrice` is < 0.005 the ico will fail
    if `TokenSalePrice` is < 0.005, `DirTweet`is >= 113 and <361, the ico will succeed
      otherwise if `TokenSalePrice` is < 0.005, `DirTweet`is >= 113 and >=361, the ico will fail
      otherwise if `TokenSalePrice` is less than 0.005 and `DirTweet`is < 113, the ico will fail

If your `Tvolume` is >= 73, the ico will succeed
  otherwise if `Tvolume` is less than 73, the ico will fail
  
# 4. Report the accuracy, sensitivity and specificity of the tree (after pruning, using testing set)

```{r}
table(predict_tree, testset$USDRaised)
```

```{r}
tp = 12
tn = 13
fp = 2
fn = 2
actual_p = tp + tn
actual_n = fn + fp
all = tp + tn + fp + fn

accuracy = (tp + tn) / all
sensitivity = tp / actual_p
specificity = tn / actual_n
print(c("accuracy ", accuracy, "sensitivity", sensitivity, "specificity", specificity))
```
# 5. Build a random forest with 500 trees, and select 5 variables each time, report the accuracy of the forest and variable importance. 
## Set.seed(100)
```{r}
set.seed(100)
```
## change the target variable to factor. 
```{r}
df[,c(9)]<-lapply( df[ ,c(9)],factor)
```
## Build a random forest with 500 trees, and select 5 variables each time
```{r}
Ran <-randomForest( USDRaised ~.,  data=df, na.action=na.omit ,  ntree=500,
                   importance=TRUE, mtry=5)
Ran
```
## report the accuracy of the forest 
```{r}
tp = 57
tn = 54
fp = 16
fn = 17
actual_p = tp + tn
actual_n = fn + fp
all = tp + tn + fp + fn
accuracy = (tp + tn) / all

print(c("accuracy ", accuracy))
```

## variable importance
```{r}
varImpPlot(Ran)
```